{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "297f1382-6b8d-457f-8230-955e16f5b8a5",
   "metadata": {},
   "source": [
    "# 🔬 Advanced Research Analysis & ML Prediction System\n",
    "\n",
    "## COMPLETE SELF-CONTAINED ADVANCED LIPID ANALYSIS PIPELINE\n",
    "# =========================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a712dda8-14a0-4c0b-9753-406364bc3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4552a3-a58c-4a4d-9842-4c699a976e17",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COMPLETE SELF-CONTAINED ADVANCED LIPID ANALYSIS PIPELINE\n",
    "# =========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Draw, AllChem, PandasTools\n",
    "from rdkit import DataStructs\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# BASE PIPELINE CLASS\n",
    "class EnhancedLipidPipeline:\n",
    "    \"\"\"Complete enhanced lipid analysis pipeline with all four improvements\"\"\"\n",
    "    \n",
    "    def __init__(self, sdf_path):\n",
    "        self.sdf_path = sdf_path\n",
    "        self.df = None\n",
    "        self.search_engine = None\n",
    "        \n",
    "    def run_complete_analysis(self, sample_size=None):\n",
    "        \"\"\"Run the complete enhanced analysis pipeline\"\"\"\n",
    "        print(\"🚀 STARTING ENHANCED LIPID MAPS ANALYSIS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # 1. Load and preprocess data\n",
    "        if not self._load_data(sample_size):\n",
    "            return False\n",
    "            \n",
    "        # 2. Apply all enhancements\n",
    "        self._apply_official_classification()\n",
    "        self._validate_exact_mass()\n",
    "        self._add_external_links()\n",
    "        \n",
    "        print(\"✅ ENHANCED PIPELINE READY!\")\n",
    "        self._print_summary()\n",
    "        return True\n",
    "    \n",
    "    def _load_data(self, sample_size):\n",
    "        \"\"\"Load SDF data with error handling\"\"\"\n",
    "        try:\n",
    "            self.df = PandasTools.LoadSDF(self.sdf_path, \n",
    "                                        molColName='Molecule',\n",
    "                                        smilesName='SMILES',\n",
    "                                        strictParsing=False)\n",
    "            \n",
    "            if sample_size and sample_size < len(self.df):\n",
    "                self.df = self.df.sample(sample_size, random_state=42)\n",
    "                \n",
    "            print(f\"📥 Loaded {len(self.df)} lipid structures\")\n",
    "            \n",
    "            # Calculate basic properties\n",
    "            self._calculate_molecular_properties()\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading data: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _calculate_molecular_properties(self):\n",
    "        \"\"\"Calculate basic molecular properties\"\"\"\n",
    "        properties = {\n",
    "            'Molecular_Weight': Descriptors.MolWt,\n",
    "            'LogP': Descriptors.MolLogP,\n",
    "            'TPSA': Descriptors.TPSA,\n",
    "            'HBD': Descriptors.NumHDonors,\n",
    "            'HBA': Descriptors.NumHAcceptors\n",
    "        }\n",
    "        \n",
    "        for prop_name, prop_func in properties.items():\n",
    "            self.df[prop_name] = self.df['Molecule'].apply(\n",
    "                lambda x: prop_func(x) if x else None\n",
    "            )\n",
    "    \n",
    "    def _apply_official_classification(self):\n",
    "        \"\"\"Apply official LIPID MAPS classification\"\"\"\n",
    "        print(\"🏷️ Applying official classification...\")\n",
    "        \n",
    "        # Look for LM_ID column\n",
    "        if 'LM_ID' in self.df.columns:\n",
    "            self.df['parsed_lm_id'] = self.df['LM_ID'].apply(self._parse_lm_id)\n",
    "            \n",
    "            # Extract classification components\n",
    "            self.df['category_code'] = self.df['parsed_lm_id'].apply(\n",
    "                lambda x: x.get('category_code') if x else None\n",
    "            )\n",
    "            self.df['class_code'] = self.df['parsed_lm_id'].apply(\n",
    "                lambda x: x.get('class_code') if x else None\n",
    "            )\n",
    "            \n",
    "            print(f\"   Parsed {self.df['category_code'].notna().sum()} LM_IDs\")\n",
    "    \n",
    "    def _parse_lm_id(self, lm_id):\n",
    "        \"\"\"Parse LIPID MAPS ID\"\"\"\n",
    "        if not lm_id or not isinstance(lm_id, str) or not lm_id.startswith('LM'):\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            return {\n",
    "                'category_code': lm_id[2:4],\n",
    "                'class_code': lm_id[4:6],\n",
    "                'subclass_code': lm_id[6:8]\n",
    "            }\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def _validate_exact_mass(self):\n",
    "        \"\"\"Validate exact mass accuracy\"\"\"\n",
    "        if 'EXACT_MASS' not in self.df.columns:\n",
    "            print(\"⚠️  No EXACT_MASS column found for validation\")\n",
    "            return\n",
    "            \n",
    "        print(\"⚖️ Validating exact masses...\")\n",
    "        \n",
    "        validations = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            valid = self._validate_single_mass(row)\n",
    "            validations.append(valid)\n",
    "        \n",
    "        validation_df = pd.DataFrame(validations)\n",
    "        self.df['mass_valid'] = validation_df['valid']\n",
    "        self.df['mass_discrepancy'] = validation_df['discrepancy']\n",
    "        \n",
    "        valid_count = validation_df['valid'].sum()\n",
    "        print(f\"   Mass validation: {valid_count}/{len(validation_df)} valid\")\n",
    "    \n",
    "    def _validate_single_mass(self, row):\n",
    "        \"\"\"Validate mass for a single lipid\"\"\"\n",
    "        try:\n",
    "            reported = float(row['EXACT_MASS'])\n",
    "            calculated = Descriptors.ExactMolWt(row['Molecule']) if row['Molecule'] else None\n",
    "            \n",
    "            if calculated is None:\n",
    "                return {'valid': False, 'discrepancy': None}\n",
    "                \n",
    "            discrepancy = abs(reported - calculated)\n",
    "            valid = discrepancy <= 0.01  # 0.01 Da tolerance\n",
    "            \n",
    "            return {'valid': valid, 'discrepancy': discrepancy}\n",
    "            \n",
    "        except:\n",
    "            return {'valid': False, 'discrepancy': None}\n",
    "    \n",
    "    def _add_external_links(self):\n",
    "        \"\"\"Add external database links\"\"\"\n",
    "        print(\"🔗 Adding external database links...\")\n",
    "        \n",
    "        databases = {\n",
    "            'PUBCHEM_CID': 'https://pubchem.ncbi.nlm.nih.gov/compound/{}',\n",
    "            'HMDB_ID': 'https://hmdb.ca/metabolites/{}',\n",
    "            'KEGG_ID': 'https://www.genome.jp/dbget-bin/www_bget?{}',\n",
    "            'CHEBI_ID': 'https://www.ebi.ac.uk/chebi/searchId.do?chebiId=CHEBI:{}'\n",
    "        }\n",
    "        \n",
    "        for db_id, url_template in databases.items():\n",
    "            if db_id in self.df.columns:\n",
    "                link_col = f'{db_id}_LINK'\n",
    "                self.df[link_col] = self.df[db_id].apply(\n",
    "                    lambda x: url_template.format(x) if pd.notna(x) else None\n",
    "                )\n",
    "                \n",
    "                available = self.df[link_col].notna().sum()\n",
    "                print(f\"   {db_id}: {available} links\")\n",
    "    \n",
    "    def _print_summary(self):\n",
    "        \"\"\"Print pipeline summary\"\"\"\n",
    "        print(\"\\n📊 PIPELINE SUMMARY:\")\n",
    "        print(f\"   Total lipids: {len(self.df):,}\")\n",
    "        \n",
    "        if 'category_code' in self.df.columns:\n",
    "            categories = self.df['category_code'].value_counts()\n",
    "            print(f\"   Lipid categories: {len(categories)}\")\n",
    "            \n",
    "        if 'mass_valid' in self.df.columns:\n",
    "            valid_pct = self.df['mass_valid'].mean() * 100\n",
    "            print(f\"   Valid masses: {valid_pct:.1f}%\")\n",
    "        \n",
    "        link_cols = [col for col in self.df.columns if col.endswith('_LINK')]\n",
    "        total_links = sum(self.df[col].notna().sum() for col in link_cols)\n",
    "        print(f\"   External links: {total_links}\")\n",
    "\n",
    "# RESEARCH ANALYZER CLASS\n",
    "class LipidResearchAnalyzer:\n",
    "    \"\"\"Advanced research analysis for lipidomics data\"\"\"\n",
    "    \n",
    "    def __init__(self, lipid_pipeline):\n",
    "        self.pipeline = lipid_pipeline\n",
    "        self.df = lipid_pipeline.df\n",
    "        self.analysis_results = {}\n",
    "        \n",
    "    def comprehensive_lipid_analysis(self):\n",
    "        \"\"\"Run comprehensive research-focused lipid analysis\"\"\"\n",
    "        print(\"🔬 STARTING COMPREHENSIVE LIPID RESEARCH ANALYSIS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        analyses = [\n",
    "            self._analyze_lipid_class_distribution,\n",
    "            self._analyze_chemical_space,\n",
    "            self._analyze_property_correlations,\n",
    "            self._analyze_lipid_class_characteristics,\n",
    "            self._analyze_biosynthetic_families\n",
    "        ]\n",
    "        \n",
    "        for analysis in analyses:\n",
    "            try:\n",
    "                analysis()\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Analysis {analysis.__name__} failed: {e}\")\n",
    "        \n",
    "        self._generate_research_report()\n",
    "        \n",
    "    def _analyze_lipid_class_distribution(self):\n",
    "        \"\"\"Detailed analysis of lipid class distribution\"\"\"\n",
    "        print(\"📊 Analyzing lipid class distribution...\")\n",
    "        \n",
    "        if 'CATEGORY' in self.df.columns:\n",
    "            # Main category distribution\n",
    "            category_dist = self.df['CATEGORY'].value_counts()\n",
    "            self.analysis_results['category_distribution'] = category_dist\n",
    "            \n",
    "            # Molecular property distribution by category\n",
    "            category_stats = self.df.groupby('CATEGORY').agg({\n",
    "                'Molecular_Weight': ['mean', 'std', 'min', 'max'],\n",
    "                'LogP': ['mean', 'std', 'min', 'max'],\n",
    "                'TPSA': ['mean', 'std']\n",
    "            }).round(2)\n",
    "            \n",
    "            self.analysis_results['category_property_stats'] = category_stats\n",
    "            \n",
    "            print(f\"   Found {len(category_dist)} lipid categories\")\n",
    "            for category, count in category_dist.head(10).items():\n",
    "                print(f\"   {category}: {count} lipids\")\n",
    "    \n",
    "    def _analyze_chemical_space(self):\n",
    "        \"\"\"Analyze lipid chemical space using PCA\"\"\"\n",
    "        print(\"🧪 Analyzing chemical space with PCA...\")\n",
    "        \n",
    "        # Select numeric properties for PCA\n",
    "        numeric_cols = ['Molecular_Weight', 'LogP', 'TPSA', 'HBD', 'HBA']\n",
    "        available_numeric = [col for col in numeric_cols if col in self.df.columns]\n",
    "        \n",
    "        if len(available_numeric) >= 2:\n",
    "            X = self.df[available_numeric].dropna()\n",
    "            \n",
    "            if len(X) > 10:  # Enough data for PCA\n",
    "                # Standardize features\n",
    "                scaler = StandardScaler()\n",
    "                X_scaled = scaler.fit_transform(X)\n",
    "                \n",
    "                # Perform PCA\n",
    "                pca = PCA(n_components=2)\n",
    "                X_pca = pca.fit_transform(X_scaled)\n",
    "                \n",
    "                self.analysis_results['pca'] = {\n",
    "                    'components': X_pca,\n",
    "                    'explained_variance': pca.explained_variance_ratio_,\n",
    "                    'features': available_numeric\n",
    "                }\n",
    "                \n",
    "                print(f\"   PCA explained variance: {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "    \n",
    "    def _analyze_property_correlations(self):\n",
    "        \"\"\"Analyze correlations between molecular properties\"\"\"\n",
    "        print(\"📈 Analyzing property correlations...\")\n",
    "        \n",
    "        numeric_cols = ['Molecular_Weight', 'LogP', 'TPSA', 'HBD', 'HBA']\n",
    "        available_numeric = [col for col in numeric_cols if col in self.df.columns]\n",
    "        \n",
    "        if len(available_numeric) >= 2:\n",
    "            correlation_matrix = self.df[available_numeric].corr()\n",
    "            self.analysis_results['correlation_matrix'] = correlation_matrix\n",
    "            \n",
    "            # Find strong correlations (absolute value > 0.5)\n",
    "            strong_correlations = []\n",
    "            for i in range(len(available_numeric)):\n",
    "                for j in range(i+1, len(available_numeric)):\n",
    "                    corr = correlation_matrix.iloc[i, j]\n",
    "                    if abs(corr) > 0.5:\n",
    "                        strong_correlations.append({\n",
    "                            'property1': available_numeric[i],\n",
    "                            'property2': available_numeric[j],\n",
    "                            'correlation': corr\n",
    "                        })\n",
    "            \n",
    "            self.analysis_results['strong_correlations'] = strong_correlations\n",
    "            \n",
    "            if strong_correlations:\n",
    "                print(\"   Strong correlations found:\")\n",
    "                for corr in strong_correlations[:5]:\n",
    "                    print(f\"   {corr['property1']} ↔ {corr['property2']}: {corr['correlation']:.3f}\")\n",
    "    \n",
    "    def _analyze_lipid_class_characteristics(self):\n",
    "        \"\"\"Identify characteristic properties of each lipid class\"\"\"\n",
    "        print(\"🎯 Analyzing lipid class characteristics...\")\n",
    "        \n",
    "        if 'CATEGORY' in self.df.columns:\n",
    "            characteristics = {}\n",
    "            property_cols = ['Molecular_Weight', 'LogP', 'TPSA']\n",
    "            available_props = [col for col in property_cols if col in self.df.columns]\n",
    "            \n",
    "            for category in self.df['CATEGORY'].unique():\n",
    "                category_data = self.df[self.df['CATEGORY'] == category]\n",
    "                \n",
    "                char_data = {}\n",
    "                for prop in available_props:\n",
    "                    if prop in category_data.columns:\n",
    "                        char_data[prop] = {\n",
    "                            'mean': category_data[prop].mean(),\n",
    "                            'std': category_data[prop].std(),\n",
    "                            'range': (category_data[prop].min(), category_data[prop].max())\n",
    "                        }\n",
    "                \n",
    "                # Identify most common properties\n",
    "                if len(category_data) > 0:\n",
    "                    characteristics[category] = char_data\n",
    "            \n",
    "            self.analysis_results['class_characteristics'] = characteristics\n",
    "            \n",
    "            print(f\"   Analyzed characteristics for {len(characteristics)} lipid classes\")\n",
    "    \n",
    "    def _analyze_biosynthetic_families(self):\n",
    "        \"\"\"Group lipids into biosynthetic families\"\"\"\n",
    "        print(\"🧬 Analyzing biosynthetic families...\")\n",
    "        \n",
    "        # Define biosynthetic relationships (simplified)\n",
    "        biosynthetic_families = {\n",
    "            'glycerolipid_family': ['GL', 'GP'],\n",
    "            'sphingolipid_family': ['SP'],\n",
    "            'sterol_family': ['ST'],\n",
    "            'fatty_acid_family': ['FA'],\n",
    "            'polyketide_family': ['PK']\n",
    "        }\n",
    "        \n",
    "        if 'category_code' in self.df.columns:\n",
    "            family_counts = {}\n",
    "            for family, categories in biosynthetic_families.items():\n",
    "                family_lipids = self.df[self.df['category_code'].isin(categories)]\n",
    "                family_counts[family] = len(family_lipids)\n",
    "            \n",
    "            self.analysis_results['biosynthetic_families'] = family_counts\n",
    "            \n",
    "            print(\"   Biosynthetic family counts:\")\n",
    "            for family, count in family_counts.items():\n",
    "                if count > 0:\n",
    "                    print(f\"   {family}: {count} lipids\")\n",
    "    \n",
    "    def _generate_research_report(self):\n",
    "        \"\"\"Generate comprehensive research report\"\"\"\n",
    "        print(\"\\n📋 GENERATING RESEARCH ANALYSIS REPORT\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        report = {\n",
    "            'total_lipids_analyzed': len(self.df),\n",
    "            'lipid_categories': self.df['CATEGORY'].nunique() if 'CATEGORY' in self.df.columns else 0,\n",
    "            'analysis_timestamp': pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        # Add key findings\n",
    "        if 'category_distribution' in self.analysis_results:\n",
    "            top_category = self.analysis_results['category_distribution'].index[0]\n",
    "            top_count = self.analysis_results['category_distribution'].iloc[0]\n",
    "            report['most_abundant_category'] = f\"{top_category} ({top_count} lipids)\"\n",
    "        \n",
    "        if 'strong_correlations' in self.analysis_results:\n",
    "            report['strong_correlations_found'] = len(self.analysis_results['strong_correlations'])\n",
    "        \n",
    "        if 'biosynthetic_families' in self.analysis_results:\n",
    "            report['biosynthetic_families_analyzed'] = len(self.analysis_results['biosynthetic_families'])\n",
    "        \n",
    "        self.analysis_results['research_report'] = report\n",
    "        \n",
    "        # Print summary\n",
    "        for key, value in report.items():\n",
    "            print(f\"   {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "# MACHINE LEARNING CLASS\n",
    "class LipidMachineLearning:\n",
    "    \"\"\"Fixed machine learning for lipid classification\"\"\"\n",
    "    \n",
    "    def __init__(self, lipid_pipeline):\n",
    "        self.pipeline = lipid_pipeline\n",
    "        self.df = lipid_pipeline.df\n",
    "        self.models = {}\n",
    "        \n",
    "    def prepare_ml_features(self, feature_type='descriptors'):\n",
    "        \"\"\"Prepare features for machine learning with support for multiple feature types.\n",
    "    \n",
    "        Args:\n",
    "            feature_type (str): Type of features to generate. \n",
    "                                Options: 'descriptors', 'fingerprints', 'properties'\n",
    "        \"\"\"\n",
    "        print(\"🛠️ Preparing ML features...\")\n",
    "    \n",
    "        features = []\n",
    "        feature_names = []\n",
    "    \n",
    "        if feature_type == 'descriptors':\n",
    "            # Calculate a comprehensive set of molecular descriptors\n",
    "            for mol in self.df['Molecule']:\n",
    "                if mol:\n",
    "                    # Calculate a broad set of descriptors\n",
    "                    descs = []\n",
    "                    names = []\n",
    "                    # Heavy atom count\n",
    "                    descs.append(mol.GetNumHeavyAtoms())\n",
    "                    names.append('HeavyAtomCount')\n",
    "                    # Hydrogen bond acceptors and donors\n",
    "                    descs.append(Descriptors.NumHAcceptors(mol))\n",
    "                    names.append('NumHAcceptors')\n",
    "                    descs.append(Descriptors.NumHDonors(mol))\n",
    "                    names.append('NumHDonors')\n",
    "                    # Rotatable bonds\n",
    "                    descs.append(Descriptors.NumRotatableBonds(mol))\n",
    "                    names.append('NumRotatableBonds')\n",
    "                    # Number of rings\n",
    "                    descs.append(Descriptors.RingCount(mol))\n",
    "                    names.append('RingCount')\n",
    "                    # Additional useful descriptors\n",
    "                    descs.append(Descriptors.MolLogP(mol))  # Although this is predicted, it can be a useful feature\n",
    "                    names.append('RDKit_LogP')\n",
    "                    descs.append(Descriptors.TPSA(mol))\n",
    "                    names.append('TPSA')\n",
    "                    descs.append(Descriptors.MolWt(mol))\n",
    "                    names.append('MolWt')\n",
    "                \n",
    "                    features.append(descs)\n",
    "                    if not feature_names:  # Set names only once\n",
    "                        feature_names = names\n",
    "                else:\n",
    "                    # If molecule is invalid, append a list of NaNs\n",
    "                    features.append([np.nan] * 8)  # Adjust based on number of descriptors\n",
    "        \n",
    "            print(f\"   Prepared {len(feature_names)} molecular descriptors\")\n",
    "        \n",
    "        elif feature_type == 'fingerprints':\n",
    "            # Use Morgan fingerprints (ECFP-like)\n",
    "            for mol in self.df['Molecule']:\n",
    "                if mol:\n",
    "                    # Generate Morgan fingerprint with radius 2 (equivalent to ECFP4)\n",
    "                    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024)\n",
    "                    features.append(list(fp))\n",
    "                else:\n",
    "                    features.append([0] * 1024)\n",
    "        \n",
    "            feature_names = [f'FP_{i}' for i in range(1024)]\n",
    "            print(f\"   Prepared {len(feature_names)} fingerprint bits\")\n",
    "        \n",
    "        elif feature_type == 'properties':\n",
    "            # Your original properties method for backward compatibility\n",
    "            property_cols = ['Molecular_Weight', 'LogP', 'TPSA', 'HBD', 'HBA']\n",
    "            available_props = [col for col in property_cols if col in self.df.columns]        \n",
    "            features = self.df[available_props].values\n",
    "            feature_names = available_props\n",
    "            print(f\"   Prepared {len(feature_names)} basic properties\")\n",
    "    \n",
    "        else:\n",
    "            print(f\"❌ Unsupported feature type: {feature_type}\")\n",
    "            return pd.DataFrame(), []\n",
    "    \n",
    "        # Create feature DataFrame with the SAME index as the original dataframe\n",
    "        feature_df = pd.DataFrame(features, columns=feature_names, index=self.df.index)\n",
    "    \n",
    "        # Remove columns with too many missing values\n",
    "        feature_df = feature_df.dropna(axis=1, how='all')\n",
    "    \n",
    "        # Fill remaining missing values with column median\n",
    "        for col in feature_df.columns:\n",
    "            if feature_df[col].isna().any():\n",
    "                feature_df[col] = feature_df[col].fillna(feature_df[col].median())\n",
    "    \n",
    "        print(f\"✅ Final feature matrix: {feature_df.shape[0]} samples, {feature_df.shape[1]} features\")\n",
    "        return feature_df, feature_names\n",
    "\n",
    "    \n",
    "    def train_lipid_classifier(self, target_column='CATEGORY', feature_type='properties'):\n",
    "        \"\"\"Train classifier to predict lipid category\"\"\"\n",
    "        print(f\"🎯 Training lipid classifier for {target_column}...\")\n",
    "        \n",
    "        if target_column not in self.df.columns:\n",
    "            print(f\"❌ Target column {target_column} not found\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Prepare features and target\n",
    "            X, feature_names = self.prepare_ml_features(feature_type)\n",
    "            y = self.df[target_column]\n",
    "            \n",
    "            # Find samples where both features and target are available\n",
    "            valid_mask = y.notna() & X.notna().all(axis=1)\n",
    "            \n",
    "            if valid_mask.sum() == 0:\n",
    "                print(\"❌ No valid samples for training\")\n",
    "                return None\n",
    "            \n",
    "            # Filter using the boolean mask (now indices are aligned)\n",
    "            X_filtered = X[valid_mask]\n",
    "            y_filtered = y[valid_mask]\n",
    "            \n",
    "            print(f\"   Using {len(X_filtered)} samples for training\")\n",
    "            \n",
    "            # Encode target labels\n",
    "            le = LabelEncoder()\n",
    "            y_encoded = le.fit_transform(y_filtered)\n",
    "            \n",
    "            # Split data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_filtered, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "            )\n",
    "            \n",
    "            # Scale features\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            \n",
    "            # Train Random Forest classifier\n",
    "            rf_classifier = RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            rf_classifier.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Evaluate model\n",
    "            y_pred = rf_classifier.predict(X_test_scaled)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Feature importance\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': rf_classifier.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            # Store model\n",
    "            model_key = f\"classifier_{target_column}_{feature_type}\"\n",
    "            self.models[model_key] = {\n",
    "                'model': rf_classifier,\n",
    "                'scaler': scaler,\n",
    "                'label_encoder': le,\n",
    "                'feature_names': feature_names,\n",
    "                'accuracy': accuracy,\n",
    "                'feature_importance': importance_df\n",
    "            }\n",
    "            \n",
    "            print(f\"✅ Classifier trained with {accuracy:.3f} accuracy\")\n",
    "            print(f\"   Top 3 important features:\")\n",
    "            for _, row in importance_df.head(3).iterrows():\n",
    "                print(f\"     {row['feature']}: {row['importance']:.4f}\")\n",
    "            \n",
    "            return self.models[model_key]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error training classifier: {e}\")\n",
    "            return None\n",
    "\n",
    "    def train_property_predictor(self, target_property='LogP', feature_type='descriptors'):\n",
    "        \"\"\"Train regressor to predict molecular properties with robust indexing\"\"\"\n",
    "        print(f\"📊 Training predictor for {target_property}...\")\n",
    "    \n",
    "        if target_property not in self.df.columns:\n",
    "            print(f\"❌ Target property {target_property} not found\")\n",
    "            return None\n",
    "    \n",
    "        try:\n",
    "            # Prepare features and target\n",
    "            X, feature_names = self.prepare_ml_features(feature_type)\n",
    "            y = self.df[target_property]\n",
    "        \n",
    "            # Create valid indices mask\n",
    "            valid_indices = y.notna() & X.notna().all(axis=1)\n",
    "        \n",
    "            if valid_indices.sum() == 0:\n",
    "                print(\"❌ No valid samples for training\")\n",
    "                return None\n",
    "        \n",
    "            X_filtered = X.loc[valid_indices]\n",
    "            y_filtered = y.loc[valid_indices]\n",
    "        \n",
    "            print(f\"   Using {len(X_filtered)} samples for training\")\n",
    "        \n",
    "            # Split data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_filtered, y_filtered, test_size=0.2, random_state=42\n",
    "            )\n",
    "        \n",
    "            # Scale features\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "            # Train Random Forest regressor\n",
    "            rf_regressor = RandomForestRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                random_state=42\n",
    "            )\n",
    "        \n",
    "            rf_regressor.fit(X_train_scaled, y_train)\n",
    "        \n",
    "            # Evaluate model\n",
    "            y_pred = rf_regressor.predict(X_test_scaled)\n",
    "            r2_score = rf_regressor.score(X_test_scaled, y_test)\n",
    "        \n",
    "            # Feature importance\n",
    "            importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': rf_regressor.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "        \n",
    "            # Store model and results\n",
    "            model_key = f\"regressor_{target_property}_{feature_type}\"\n",
    "            self.models[model_key] = {\n",
    "                'model': rf_regressor,\n",
    "                'scaler': scaler,\n",
    "                'feature_names': feature_names,\n",
    "                'r2_score': r2_score,\n",
    "                'feature_importance': importance_df\n",
    "            }\n",
    "        \n",
    "            print(f\"✅ Regressor trained with R² = {r2_score:.3f}\")\n",
    "            print(f\"   Top 3 important features:\")\n",
    "            for _, row in importance_df.head(3).iterrows():\n",
    "                print(f\"     {row['feature']}: {row['importance']:.4f}\")\n",
    "        \n",
    "            return self.models[model_key]\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error training regressor: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "\n",
    "    def visualize_ml_results(self):\n",
    "        \"\"\"Visualize machine learning results - FIXED VERSION\"\"\"\n",
    "        if not self.models:\n",
    "            print(\"❌ No trained models to visualize\")\n",
    "            return\n",
    "\n",
    "        for model_key, model_info in self.models.items():\n",
    "            print(f\"\\n📊 Model: {model_key}\")\n",
    "\n",
    "           # Check the model type and use the correct metric key\n",
    "           # Use .get() method to avoid KeyError, providing a default value if the key is missing :cite[4]:cite[8]\n",
    "            accuracy = model_info.get('accuracy')\n",
    "            r2_score = model_info.get('r2_score')\n",
    "\n",
    "            if accuracy is not None:\n",
    "                print(f\"   Accuracy: {accuracy:.3f}\")\n",
    "            elif r2_score is not None:\n",
    "                print(f\"   R² Score: {r2_score:.3f}\")\n",
    "            else:\n",
    "                print(f\"   Performance metric: Not available\")\n",
    "\n",
    "            # Plot feature importance\n",
    "            top_features = model_info['feature_importance'].head(10)\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.barh(range(len(top_features)), top_features['importance'])\n",
    "            plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "            plt.xlabel('Feature Importance')\n",
    "            plt.title(f'Feature Importance - {model_key}')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# ADVANCED PIPELINE CLASS (NOW WITH PROPER INHERITANCE)\n",
    "class AdvancedLipidPipeline(EnhancedLipidPipeline):\n",
    "    \"\"\"Advanced pipeline with research analysis and machine learning\"\"\"\n",
    "    \n",
    "    def __init__(self, sdf_path):\n",
    "        super().__init__(sdf_path)\n",
    "        self.research_analyzer = None\n",
    "        self.ml_predictor = None\n",
    "        \n",
    "    def run_advanced_analysis(self, sample_size=None):\n",
    "        \"\"\"Run advanced analysis with research and ML components\"\"\"\n",
    "        if not self.run_complete_analysis(sample_size):\n",
    "            return False\n",
    "    \n",
    "        # Initialize research and ML components\n",
    "        self.research_analyzer = LipidResearchAnalyzer(self)\n",
    "        self.ml_predictor = LipidMachineLearning(self)\n",
    "    \n",
    "        # ✅ ADD THIS LINE: Initialize the search engine\n",
    "        self.search_engine = EnhancedLipidSearchEngine(self.df)\n",
    "    \n",
    "        # Run research analysis\n",
    "        self.research_analyzer.comprehensive_lipid_analysis()\n",
    "\n",
    "        # Train basic ML models\n",
    "        print(\"\\n🤖 TRAINING MACHINE LEARNING MODELS\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Train classifier if category data available\n",
    "        if 'CATEGORY' in self.df.columns:\n",
    "            self.ml_predictor.train_lipid_classifier('CATEGORY', 'properties')\n",
    "        \n",
    "        # Train property predictors\n",
    "        if 'LogP' in self.df.columns:\n",
    "            self.ml_predictor.train_property_predictor('LogP', 'descriptors')\n",
    "        \n",
    "        # Visualize ML results\n",
    "        self.ml_predictor.visualize_ml_results()\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def save_trained_models(self, directory=\"saved_models\"):\n",
    "        \"\"\"Save all trained ML models to disk\"\"\"\n",
    "        import joblib\n",
    "        import os\n",
    "    \n",
    "        # Create directory if it doesn't exist\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            print(f\"📁 Created directory: {directory}\")\n",
    "    \n",
    "        if not hasattr(self, 'ml_predictor') or not self.ml_predictor.models:\n",
    "            print(\"❌ No trained models found to save\")\n",
    "            return False\n",
    "    \n",
    "        try:\n",
    "            saved_count = 0\n",
    "            timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "            # Save each model\n",
    "            for model_name, model_info in self.ml_predictor.models.items():\n",
    "                # Create safe filename\n",
    "                safe_name = model_name.replace('/', '_').replace('\\\\', '_')\n",
    "                filename = f\"{safe_name}_{timestamp}.joblib\"\n",
    "                filepath = os.path.join(directory, filename)\n",
    "            \n",
    "                # Save the model\n",
    "                joblib.dump(model_info, filepath)\n",
    "                print(f\"💾 Saved: {filename}\")\n",
    "                saved_count += 1\n",
    "        \n",
    "            print(f\"✅ Successfully saved {saved_count} models to '{directory}' folder\")\n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error saving models: {e}\")\n",
    "            return False\n",
    "\n",
    "def load_trained_models_simple(pipeline):\n",
    "    \"\"\"Simple one-click model loading for option #??\"\"\"\n",
    "    import joblib\n",
    "    import os\n",
    "    import glob\n",
    "    \n",
    "    model_dir = \"trained_models\"\n",
    "    \n",
    "    # Check if directory exists\n",
    "    if not os.path.exists(model_dir):\n",
    "        print(f\"❌ No '{model_dir}' folder found. Save models first (option 9).\")\n",
    "        return\n",
    "    \n",
    "    # Find all .joblib files\n",
    "    model_files = glob.glob(os.path.join(model_dir, \"*.joblib\"))\n",
    "    \n",
    "    if not model_files:\n",
    "        print(f\"❌ No model files found in '{model_dir}'. Save models first (option 9).\")\n",
    "        return\n",
    "    \n",
    "    print(\"📂 Available models:\")\n",
    "    for i, filepath in enumerate(model_files, 1):\n",
    "        filename = os.path.basename(filepath)\n",
    "        print(f\"   {i}. {filename}\")\n",
    "    \n",
    "    try:\n",
    "        choice = input(\"\\nChoose model to load (number) or 'all' for all models: \").strip()\n",
    "        \n",
    "        if choice.lower() == 'all':\n",
    "            # Load all models\n",
    "            loaded_count = 0\n",
    "            for filepath in model_files:\n",
    "                filename = os.path.basename(filepath)\n",
    "                try:\n",
    "                    model_info = joblib.load(filepath)\n",
    "                    model_name = os.path.splitext(filename)[0]\n",
    "                    \n",
    "                    # Ensure ml_predictor exists\n",
    "                    if not hasattr(pipeline, 'ml_predictor'):\n",
    "                        from your_ml_module import LipidMachineLearning  # Adjust import as needed\n",
    "                        pipeline.ml_predictor = LipidMachineLearning(pipeline)\n",
    "                    \n",
    "                    # Add to models dictionary\n",
    "                    pipeline.ml_predictor.models[model_name] = model_info\n",
    "                    print(f\"   ✅ Loaded: {filename}\")\n",
    "                    loaded_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ❌ Failed to load {filename}: {e}\")\n",
    "            \n",
    "            print(f\"🎉 Successfully loaded {loaded_count} models\")\n",
    "            \n",
    "        else:\n",
    "            # Load single model\n",
    "            choice_num = int(choice)\n",
    "            if 1 <= choice_num <= len(model_files):\n",
    "                filepath = model_files[choice_num - 1]\n",
    "                filename = os.path.basename(filepath)\n",
    "                \n",
    "                try:\n",
    "                    model_info = joblib.load(filepath)\n",
    "                    model_name = os.path.splitext(filename)[0]\n",
    "                    \n",
    "                    # Ensure ml_predictor exists\n",
    "                    if not hasattr(pipeline, 'ml_predictor'):\n",
    "                        from your_ml_module import LipidMachineLearning  # Adjust import as needed\n",
    "                        pipeline.ml_predictor = LipidMachineLearning(pipeline)\n",
    "                    \n",
    "                    # Add to models dictionary\n",
    "                    pipeline.ml_predictor.models[model_name] = model_info\n",
    "                    print(f\"🎉 Successfully loaded: {filename}\")\n",
    "                    print(f\"📊 Model type: {model_name.split('_')[0]}\")  # cls or reg\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error loading model: {e}\")\n",
    "            else:\n",
    "                print(\"❌ Invalid choice\")\n",
    "                \n",
    "    except ValueError:\n",
    "        print(\"❌ Please enter a valid number or 'all'\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "\n",
    "def save_trained_models_simple(pipeline):\n",
    "    \"\"\"Simple one-click model saving for option #9\"\"\"\n",
    "    import joblib\n",
    "    import os\n",
    "    import datetime\n",
    "    \n",
    "    if not hasattr(pipeline, 'ml_predictor') or not pipeline.ml_predictor.models:\n",
    "        print(\"❌ No trained models found. Train models first (options 2 or 3).\")\n",
    "        return\n",
    "    \n",
    "    # Create models directory\n",
    "    model_dir = \"trained_models\"\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # Save all models\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    saved_count = 0\n",
    "    \n",
    "    print(\"💾 Saving trained models...\")\n",
    "    \n",
    "    for model_name, model_info in pipeline.ml_predictor.models.items():\n",
    "        # Clean up the model name for filename\n",
    "        clean_name = model_name.replace('classifier_', 'cls_').replace('regressor_', 'reg_')\n",
    "        filename = f\"{clean_name}_{timestamp}.joblib\"\n",
    "        filepath = os.path.join(model_dir, filename)\n",
    "        \n",
    "        # Save the model\n",
    "        joblib.dump(model_info, filepath)\n",
    "        print(f\"   ✅ {filename}\")\n",
    "        saved_count += 1\n",
    "    \n",
    "    print(f\"🎉 Successfully saved {saved_count} models to '{model_dir}/' folder\")\n",
    "    print(f\"📁 Full path: {os.path.abspath(model_dir)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7238b5-c3ed-4146-ae61-c358b529c47a",
   "metadata": {},
   "source": [
    "## This complete, self-contained implementation now includes:\n",
    "\n",
    "- EnhancedLipidPipeline - The base pipeline with all four original enhancements\n",
    "\n",
    "- LipidResearchAnalyzer - Advanced research analysis capabilities\n",
    "\n",
    "- LipidMachineLearning - ML models for classification and prediction\n",
    "\n",
    "- AdvancedLipidPipeline - The main class that integrates everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d1aba2-59a7-4b30-bc6f-0c268169b38e",
   "metadata": {},
   "source": [
    "## 🎯 Research Questions You Can Now Answer:\n",
    "\n",
    "1. Lipid Distribution & Diversity\n",
    "- What are the most abundant lipid classes in the database?\n",
    "- How are lipids distributed across biosynthetic families?\n",
    "- What's the molecular weight range for each lipid class?\n",
    "\n",
    "2. Chemical Space Analysis\n",
    "- How do different lipid classes occupy chemical space?\n",
    "- What are the key molecular properties that distinguish lipid classes?\n",
    "- Are there clusters of structurally similar lipids?\n",
    "\n",
    "3. Property Relationships\n",
    "- How do LogP, TPSA, and molecular weight correlate?\n",
    "- What properties are characteristic of each lipid class?\n",
    "- Are there property trends across biosynthetic pathways?\n",
    "\n",
    "4. Machine Learning Applications\n",
    "- Can we predict lipid class from molecular structure?\n",
    "- Can we estimate LogP or other properties from descriptors?\n",
    "- What molecular features are most important for classification?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60dd095-e18b-4716-8d8b-453bd72d0812",
   "metadata": {},
   "source": [
    "## ENHANCED INTERACTIVE INTERFACE WITH RESEARCH QUESTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b4e248a-9ff1-41fc-9477-71496c145ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 STARTING COMPLETE LIPID RESEARCH WORKFLOW\n",
      "==================================================\n",
      "🚀 STARTING ENHANCED LIPID MAPS ANALYSIS\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:25:37] Warning: ambiguous stereochemistry - zero final chiral volume - at atom 5 ignored\n",
      "[13:25:37] Warning: ambiguous stereochemistry - zero final chiral volume - at atom 5 ignored\n",
      "[13:25:37] Warning: ambiguous stereochemistry - zero final chiral volume - at atom 5 ignored\n",
      "[13:25:37] Warning: ambiguous stereochemistry - zero final chiral volume - at atom 5 ignored\n",
      "[13:25:37] Warning: ambiguous stereochemistry - zero final chiral volume - at atom 5 ignored\n",
      "[13:25:38] Warning: ambiguous stereochemistry - opposing bonds have opposite wedging - at atom 7 ignored.\n",
      "[13:25:38] Warning: ambiguous stereochemistry - opposing bonds have opposite wedging - at atom 7 ignored.\n",
      "[13:25:38] Warning: ambiguous stereochemistry - opposing bonds have opposite wedging - at atom 3 ignored.\n",
      "[13:25:38] Warning: ambiguous stereochemistry - opposing bonds have opposite wedging - at atom 3 ignored.\n",
      "[13:25:38] Warning: conflicting stereochemistry - bond wedging contradiction - at atom 49 ignored\n",
      "[13:25:38] Warning: conflicting stereochemistry - bond wedging contradiction - at atom 52 ignored\n",
      "[13:25:38] Warning: conflicting stereochemistry - bond wedging contradiction - at atom 49 ignored\n",
      "[13:25:38] Warning: conflicting stereochemistry - bond wedging contradiction - at atom 52 ignored\n",
      "[13:25:38] Warning: conflicting stereochemistry - bond wedging contradiction - at atom 77 ignored\n",
      "[13:25:38] Warning: conflicting stereochemistry - bond wedging contradiction - at atom 77 ignored\n",
      "[13:25:38] Warning: conflicting stereochemistry - bond wedging contradiction - at atom 81 ignored\n",
      "[13:25:38] Warning: conflicting stereochemistry - bond wedging contradiction - at atom 81 ignored\n",
      "[13:25:38] Warning: ambiguous stereochemistry - opposing bonds have opposite wedging - at atom 34 ignored.\n",
      "[13:25:38] Warning: ambiguous stereochemistry - opposing bonds have opposite wedging - at atom 34 ignored.\n",
      "[13:25:38] Warning: ambiguous stereochemistry - opposing bonds have opposite wedging - at atom 4 ignored.\n",
      "[13:25:38] Warning: ambiguous stereochemistry - opposing bonds have opposite wedging - at atom 4 ignored.\n",
      "[13:25:45] Warning: conflicting stereochemistry - bond wedging contradiction - at atom 56 ignored\n",
      "[13:25:45] Warning: conflicting stereochemistry - bond wedging contradiction - at atom 56 ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loaded 1000 lipid structures\n",
      "🏷️ Applying official classification...\n",
      "   Parsed 1000 LM_IDs\n",
      "⚖️ Validating exact masses...\n",
      "   Mass validation: 1000/1000 valid\n",
      "🔗 Adding external database links...\n",
      "   PUBCHEM_CID: 989 links\n",
      "   HMDB_ID: 144 links\n",
      "   KEGG_ID: 43 links\n",
      "   CHEBI_ID: 267 links\n",
      "✅ ENHANCED PIPELINE READY!\n",
      "\n",
      "📊 PIPELINE SUMMARY:\n",
      "   Total lipids: 1,000\n",
      "   Lipid categories: 8\n",
      "   Valid masses: 100.0%\n",
      "   External links: 1443\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EnhancedLipidSearchEngine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 355\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# Run the complete workflow\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[43mrun_complete_research_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 342\u001b[39m, in \u001b[36mrun_complete_research_workflow\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    339\u001b[39m advanced_pipeline = AdvancedLipidPipeline(\u001b[33m\"\u001b[39m\u001b[33mLMSD.sdf/structures.sdf\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# Run complete analysis\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m success = \u001b[43madvanced_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_advanced_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m    345\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🎉 PIPELINE READY FOR RESEARCH QUESTIONS!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 700\u001b[39m, in \u001b[36mAdvancedLipidPipeline.run_advanced_analysis\u001b[39m\u001b[34m(self, sample_size)\u001b[39m\n\u001b[32m    697\u001b[39m \u001b[38;5;28mself\u001b[39m.ml_predictor = LipidMachineLearning(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    699\u001b[39m \u001b[38;5;66;03m# ✅ ADD THIS LINE: Initialize the search engine\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m \u001b[38;5;28mself\u001b[39m.search_engine = \u001b[43mEnhancedLipidSearchEngine\u001b[49m(\u001b[38;5;28mself\u001b[39m.df)\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Run research analysis\u001b[39;00m\n\u001b[32m    703\u001b[39m \u001b[38;5;28mself\u001b[39m.research_analyzer.comprehensive_lipid_analysis()\n",
      "\u001b[31mNameError\u001b[39m: name 'EnhancedLipidSearchEngine' is not defined"
     ]
    }
   ],
   "source": [
    "# ENHANCED INTERACTIVE INTERFACE WITH RESEARCH QUESTIONS\n",
    "def advanced_research_interface(pipeline):\n",
    "    \"\"\"Interactive interface for advanced research and ML - ENHANCED VERSION\"\"\"\n",
    "    \n",
    "    print(\"\\n🔬 ADVANCED RESEARCH & ML INTERFACE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nResearch Options:\")\n",
    "        print(\"1. Run Comprehensive Analysis\")\n",
    "        print(\"2. Load Trained Models\")  # ← NEW OPTION\n",
    "        print(\"3. Train Lipid Classifier\")\n",
    "        print(\"4. Train Property Predictor\") \n",
    "        print(\"5. Predict Lipid Class (SMILES)\")\n",
    "        print(\"6. Show Research Findings\")\n",
    "        print(\"7. Visualize Chemical Space\")\n",
    "        print(\"8. --- ANSWER RESEARCH QUESTIONS ---\")\n",
    "        print(\"   8a. GP vs SP Property Distribution\")\n",
    "        print(\"   8b. Find Similar Lipids (SMILES)\")\n",
    "        print(\"   8c. Show Key Classifier Descriptors\")\n",
    "        print(\"   8d. Validate ML Model Accuracy\")\n",
    "        print(\"9. Export Analysis Results\")\n",
    "        print(\"10. Save Trained Models\")  # ← ADD THIS LINE\n",
    "        print(\"11. Back to Main Menu\")\n",
    "        \n",
    "        choice = input(\"\\nChoose option (1-10): \").strip().lower()\n",
    "        \n",
    "        if choice == '1':\n",
    "            pipeline.research_analyzer.comprehensive_lipid_analysis()\n",
    "        \n",
    "        elif choice == '2':  # Load Trained Models\n",
    "            load_trained_models_simple(pipeline)\n",
    "            \n",
    "        elif choice == '3':\n",
    "            if pipeline.ml_predictor:\n",
    "                target = input(\"Target column (default CATEGORY): \") or \"CATEGORY\"\n",
    "                features = input(\"Feature type (properties/descriptors/fingerprints): \") or \"properties\"\n",
    "                pipeline.ml_predictor.train_lipid_classifier(target, features)\n",
    "                pipeline.save_trained_models()\n",
    "                \n",
    "        elif choice == '4':\n",
    "            if pipeline.ml_predictor:\n",
    "                target = input(\"Target property (default LogP): \") or \"LogP\"\n",
    "                features = input(\"Feature type (properties/descriptors/fingerprints): \") or \"descriptors\"\n",
    "                pipeline.ml_predictor.train_property_predictor(target, features)\n",
    "                pipeline.save_trained_models()\n",
    "                \n",
    "        elif choice == '5':\n",
    "            if pipeline.ml_predictor:\n",
    "                smiles = input(\"Enter SMILES string: \").strip()\n",
    "                result = pipeline.ml_predictor.predict_lipid_class(smiles)\n",
    "                if result:\n",
    "                    print(f\"🎯 Predicted class: {result['predicted_class']}\")\n",
    "                    print(\"Top predictions:\")\n",
    "                    for class_name, prob in result['top_classes']:\n",
    "                        print(f\"   {class_name}: {prob:.3f}\")\n",
    "        \n",
    "        # ... (keep other existing options the same as before) ...\n",
    "        \n",
    "        elif choice == '6':\n",
    "            if pipeline.research_analyzer and pipeline.research_analyzer.analysis_results:\n",
    "                print(\"\\n📋 RESEARCH FINDINGS SUMMARY:\")\n",
    "                for key, value in pipeline.research_analyzer.analysis_results.get('research_report', {}).items():\n",
    "                    print(f\"   {key.replace('_', ' ').title()}: {value}\")\n",
    "        \n",
    "        elif choice == '7':\n",
    "            if pipeline.research_analyzer and 'pca' in pipeline.research_analyzer.analysis_results:\n",
    "                pca_data = pipeline.research_analyzer.analysis_results['pca']\n",
    "                \n",
    "                plt.figure(figsize=(10, 8))\n",
    "                scatter = plt.scatter(pca_data['components'][:, 0], pca_data['components'][:, 1], alpha=0.6)\n",
    "                plt.xlabel(f'PC1 ({pca_data[\"explained_variance\"][0]:.2%} variance)')\n",
    "                plt.ylabel(f'PC2 ({pca_data[\"explained_variance\"][1]:.2%} variance)')\n",
    "                plt.title('Lipid Chemical Space (PCA)')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.show()\n",
    "        \n",
    "        # NEW: INTEGRATED RESEARCH QUESTION ANSWERS\n",
    "        elif choice == '8a':\n",
    "            answer_gp_vs_sp_distribution(pipeline)\n",
    "        \n",
    "        elif choice == '8b':\n",
    "            answer_similarity_prediction(pipeline)\n",
    "        \n",
    "        elif choice == '8c':\n",
    "            answer_key_descriptors(pipeline)\n",
    "        \n",
    "        elif choice == '8d':\n",
    "            answer_model_accuracy(pipeline)\n",
    "        \n",
    "        elif choice == '9':\n",
    "            if pipeline.research_analyzer:\n",
    "                timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                filename = f\"lipid_research_analysis_{timestamp}.xlsx\"\n",
    "                \n",
    "                with pd.ExcelWriter(filename) as writer:\n",
    "                    # Save analysis results\n",
    "                    for result_name, result_data in pipeline.research_analyzer.analysis_results.items():\n",
    "                        if isinstance(result_data, pd.DataFrame):\n",
    "                            result_data.to_excel(writer, sheet_name=result_name[:31])\n",
    "                    \n",
    "                    # Save ML results\n",
    "                    for model_name, model_data in pipeline.ml_predictor.models.items():\n",
    "                        if 'feature_importance' in model_data:\n",
    "                            model_data['feature_importance'].to_excel(writer, sheet_name=f\"ML_{model_name}\"[:31])\n",
    "                \n",
    "                print(f\"💾 Analysis exported to {filename}\")\n",
    "\n",
    "        elif choice == '10':\n",
    "            save_trained_models_simple(pipeline)\n",
    "\n",
    "        elif choice == '11':\n",
    "            print(\"👋 Exiting research interface\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"❌ Invalid choice\")\n",
    "\n",
    "# RESEARCH QUESTION IMPLEMENTATIONS\n",
    "def answer_gp_vs_sp_distribution(pipeline):\n",
    "    \"\"\"Answer research question 1: Property distribution of glycerophospholipids vs sphingolipids\"\"\"\n",
    "    print(\"\\n📊 RESEARCH QUESTION 1: GP vs SP Property Distribution\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    df = pipeline.df\n",
    "    \n",
    "    if 'CATEGORY' not in df.columns:\n",
    "        print(\"❌ No category data available\")\n",
    "        return\n",
    "    \n",
    "    # Extract the two lipid classes of interest\n",
    "    gp_data = df[df['CATEGORY'] == 'Glycerophospholipids [GP]']\n",
    "    sp_data = df[df['CATEGORY'] == 'Sphingolipids [SP]']\n",
    "    \n",
    "    print(f\"📈 Sample sizes:\")\n",
    "    print(f\"   Glycerophospholipids (GP): {len(gp_data)} lipids\")\n",
    "    print(f\"   Sphingolipids (SP): {len(sp_data)} lipids\")\n",
    "    \n",
    "    if len(gp_data) == 0 or len(sp_data) == 0:\n",
    "        print(\"❌ Not enough data for comparison\")\n",
    "        return\n",
    "    \n",
    "    # Compare key properties\n",
    "    properties = ['Molecular_Weight', 'LogP', 'TPSA']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Property Distribution: Glycerophospholipids vs Sphingolipids', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, prop in enumerate(properties):\n",
    "        if prop in df.columns:\n",
    "            ax = axes[i//2, i%2]\n",
    "            \n",
    "            # Create comparative histograms\n",
    "            gp_prop = gp_data[prop].dropna()\n",
    "            sp_prop = sp_data[prop].dropna()\n",
    "            \n",
    "            ax.hist(gp_prop, bins=20, alpha=0.7, label='Glycerophospholipids', color='blue')\n",
    "            ax.hist(sp_prop, bins=20, alpha=0.7, label='Sphingolipids', color='red')\n",
    "            ax.set_xlabel(prop)\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.set_title(f'{prop} Distribution')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Print statistics\n",
    "            print(f\"\\n📋 {prop} Statistics:\")\n",
    "            print(f\"   GP - Mean: {gp_prop.mean():.2f}, Std: {gp_prop.std():.2f}\")\n",
    "            print(f\"   SP - Mean: {sp_prop.mean():.2f}, Std: {sp_prop.std():.2f}\")\n",
    "    \n",
    "    # Hide unused subplot\n",
    "    if len(properties) < 4:\n",
    "        axes[1, 1].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional insights\n",
    "    print(f\"\\n💡 Biological Insights:\")\n",
    "    print(f\"   GP: Major membrane components with diverse head groups\")\n",
    "    print(f\"   SP: Structural roles with ceramide backbone + head groups\")\n",
    "\n",
    "def answer_similarity_prediction(pipeline):\n",
    "    \"\"\"Answer research question 2: Predict novel lipids based on chemical similarity\"\"\"\n",
    "    print(\"\\n🔍 RESEARCH QUESTION 2: Similarity-Based Lipid Prediction\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Enhanced check with clearer error message\n",
    "    if not hasattr(pipeline, 'search_engine') or pipeline.search_engine is None:\n",
    "        print(\"❌ Search engine not available. The pipeline was not properly initialized.\")\n",
    "        print(\"💡 Please ensure 'run_advanced_analysis()' completes successfully.\")\n",
    "        return\n",
    "\n",
    "    # Get a query SMILES - you can modify this for different lipids\n",
    "    default_smiles = \"CCCCCCCCCCCCCCCCCC(=O)O\"  # Stearic acid\n",
    "    smiles = input(f\"Enter query SMILES (default: {default_smiles}): \").strip() or default_smiles\n",
    "    \n",
    "    threshold = float(input(\"Similarity threshold (0-1, default 0.7): \") or \"0.7\")\n",
    "    max_results = int(input(\"Max results (default 10): \") or \"10\")\n",
    "    \n",
    "    print(f\"🔍 Searching for lipids similar to: {smiles}\")\n",
    "    \n",
    "    # Use the similarity search functionality\n",
    "    results = pipeline.search_engine.search_by_similarity(smiles, threshold, max_results)\n",
    "    \n",
    "    if len(results) > 0:\n",
    "        print(f\"✅ Found {len(results)} similar lipids\")\n",
    "        \n",
    "        # Display results\n",
    "        display_cols = []\n",
    "        for col in results.columns:\n",
    "            if col in ['LM_ID', 'COMMON_NAME', 'CATEGORY', 'Molecular_Weight', 'Similarity']:\n",
    "                display_cols.append(col)\n",
    "        \n",
    "        display(results[display_cols].head(max_results))\n",
    "        \n",
    "        # Show molecular structures if available\n",
    "        if 'Molecule' in results.columns:\n",
    "            print(f\"\\n🖼️ Top {min(3, len(results))} similar lipid structures:\")\n",
    "            molecules_to_show = results['Molecule'].head(3).tolist()\n",
    "            legends = [f\"{row['COMMON_NAME']} (Sim: {row['Similarity']:.3f})\" \n",
    "                      for _, row in results.head(3).iterrows()]\n",
    "            \n",
    "            try:\n",
    "                img = Draw.MolsToGridImage(molecules_to_show, \n",
    "                                          molsPerRow=3, \n",
    "                                          subImgSize=(300, 300), \n",
    "                                          legends=legends)\n",
    "                display(img)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Could not display molecules: {e}\")\n",
    "    else:\n",
    "        print(\"❌ No similar lipids found. Try lowering the similarity threshold.\")\n",
    "\n",
    "def answer_key_descriptors(pipeline):\n",
    "    \"\"\"Answer research question 3: Key descriptors that differentiate lipid classes\"\"\"\n",
    "    print(\"\\n🎯 RESEARCH QUESTION 3: Key Classifier Descriptors\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not pipeline.ml_predictor or not pipeline.ml_predictor.models:\n",
    "        print(\"❌ No trained ML models found\")\n",
    "        return\n",
    "    \n",
    "    # Find classifier models\n",
    "    classifier_models = {k: v for k, v in pipeline.ml_predictor.models.items() \n",
    "                        if k.startswith('classifier')}\n",
    "    \n",
    "    if not classifier_models:\n",
    "        print(\"❌ No classifier models available\")\n",
    "        return\n",
    "    \n",
    "    for model_key, model_info in classifier_models.items():\n",
    "        print(f\"\\n📊 Model: {model_key}\")\n",
    "        print(f\"   Accuracy: {model_info.get('accuracy', 'N/A'):.3f}\")\n",
    "        \n",
    "        # Display feature importance\n",
    "        importance_df = model_info['feature_importance']\n",
    "        print(f\"\\n🔑 Top 5 Most Important Descriptors:\")\n",
    "        for idx, row in importance_df.head(5).iterrows():\n",
    "            print(f\"   {row['feature']}: {row['importance']:.4f}\")\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        top_features = importance_df.head(10)\n",
    "        \n",
    "        plt.barh(range(len(top_features)), top_features['importance'])\n",
    "        plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title(f'Key Descriptors for Lipid Classification\\n{model_key}')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Interpretation\n",
    "        print(f\"\\n💡 Interpretation:\")\n",
    "        top_desc = importance_df.iloc[0]['feature']\n",
    "        print(f\"   {top_desc} is the most important descriptor for lipid classification\")\n",
    "        print(f\"   This suggests lipid classes differ primarily in their {top_desc.lower()} characteristics\")\n",
    "\n",
    "def answer_model_accuracy(pipeline):\n",
    "    \"\"\"Answer research question 4: ML model accuracy for lipid classification\"\"\"\n",
    "    print(\"\\n🤖 RESEARCH QUESTION 4: ML Model Accuracy Validation\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not pipeline.ml_predictor or not pipeline.ml_predictor.models:\n",
    "        print(\"❌ No trained ML models found\")\n",
    "        return\n",
    "    \n",
    "    classifier_models = {k: v for k, v in pipeline.ml_predictor.models.items() \n",
    "                        if k.startswith('classifier')}\n",
    "    \n",
    "    if not classifier_models:\n",
    "        print(\"❌ No classifier models available\")\n",
    "        return\n",
    "    \n",
    "    print(\"📈 MODEL PERFORMANCE SUMMARY:\")\n",
    "    \n",
    "    for model_key, model_info in classifier_models.items():\n",
    "        accuracy = model_info.get('accuracy', 0)\n",
    "        cv_scores = model_info.get('cv_scores', [])\n",
    "        \n",
    "        print(f\"\\n🧪 {model_key}:\")\n",
    "        print(f\"   Accuracy: {accuracy:.3f}\")\n",
    "        \n",
    "        if len(cv_scores) > 0:\n",
    "            print(f\"   Cross-validation: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n",
    "        \n",
    "        # Performance interpretation\n",
    "        if accuracy >= 0.85:\n",
    "            rating = \"Excellent\"\n",
    "        elif accuracy >= 0.75:\n",
    "            rating = \"Good\"\n",
    "        elif accuracy >= 0.65:\n",
    "            rating = \"Moderate\"\n",
    "        else:\n",
    "            rating = \"Needs improvement\"\n",
    "        \n",
    "        print(f\"   Performance: {rating}\")\n",
    "        \n",
    "        # Compare with literature benchmarks\n",
    "        print(f\"   📚 Literature context: ML lipid classifiers often achieve 80-90% accuracy :cite[1]:cite[9]\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    avg_accuracy = np.mean([model.get('accuracy', 0) for model in classifier_models.values()])\n",
    "    print(f\"\\n📊 OVERALL ASSESSMENT:\")\n",
    "    print(f\"   Average accuracy: {avg_accuracy:.3f}\")\n",
    "    print(f\"   Your models are {'competitive with' if avg_accuracy >= 0.80 else 'below'} literature standards\")\n",
    "\n",
    "# FINAL INTEGRATION - YOUR COMPLETE WORKFLOW\n",
    "def run_complete_research_workflow():\n",
    "    \"\"\"Run the complete research workflow with all your questions integrated\"\"\"\n",
    "    \n",
    "    print(\"🚀 STARTING COMPLETE LIPID RESEARCH WORKFLOW\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Import warnings to keep output clean\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    \n",
    "    # Initialize pipeline\n",
    "    advanced_pipeline = AdvancedLipidPipeline(\"LMSD.sdf/structures.sdf\")\n",
    "    \n",
    "    # Run complete analysis\n",
    "    success = advanced_pipeline.run_advanced_analysis(sample_size=1000)\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n🎉 PIPELINE READY FOR RESEARCH QUESTIONS!\")\n",
    "        print(\"Now you can explore your specific research questions interactively.\")\n",
    "        \n",
    "        # Start the enhanced interface\n",
    "        advanced_research_interface(advanced_pipeline)\n",
    "    else:\n",
    "        print(\"❌ Pipeline initialization failed\")\n",
    "\n",
    "# Run the complete workflow\n",
    "if __name__ == \"__main__\":\n",
    "    run_complete_research_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b824af0-d385-49c8-8358-77ce09bb39f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
